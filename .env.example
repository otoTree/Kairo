# Server Configuration
PORT=3000
KAIRO_TOKEN=kairo_default_secret
SQLITE_DB_PATH=kairo.db

# -----------------------------------------------------------------------------
# AI Configuration (LLM & Embedding)
# -----------------------------------------------------------------------------

# Primary Provider (OpenAI Compatible Interface)
# Used for Chat/Reasoning tasks
# Examples:
# - DeepSeek: https://api.deepseek.com/v1 (Model: deepseek-chat)
# - OpenAI: https://api.openai.com/v1 (Model: gpt-4-turbo)
# - Local OpenAI Compatible: http://localhost:1234/v1
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_BASE_URL=https://api.deepseek.com/v1
OPENAI_MODEL_NAME=deepseek-chat

# Embedding Provider (OpenAI Compatible Interface)
# REQUIRED for Memory (MemCube) functionality.
# Can be the same as Primary Provider if it supports embeddings, or a different one.
# If using a separate embedding provider, configure these variables:
OPENAI_EMBEDDING_API_KEY=sk-your-embedding-api-key
OPENAI_EMBEDDING_BASE_URL=https://api.openai.com/v1
OPENAI_EMBEDDING_MODEL_NAME=text-embedding-3-small

# -----------------------------------------------------------------------------
# Ollama Configuration (Optional)
# -----------------------------------------------------------------------------
# Used if you want to use local models via OllamaProvider
# To use Ollama for embeddings, ensure you have pulled the model: `ollama pull nomic-embed-text`
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=qwen2.5:7b
OLLAMA_EMBEDDING_MODEL_NAME=nomic-embed-text

# -----------------------------------------------------------------------------
# Environment Paths (Optional Overrides)
# -----------------------------------------------------------------------------
# PYTHON_ENV_PATH=/path/to/kairo_python_env
